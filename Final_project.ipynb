{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install required libraries\n",
        "!pip install transformers datasets peft torch sentence-transformers evaluate rouge_score matplotlib seaborn\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from evaluate import load\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Verify GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "id": "LoqlRCdUgcVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    dataset = load_dataset(\"stanfordnlp/sst2\")\n",
        "    print(\"Dataset loaded:\", dataset)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n",
        "    raise SystemExit(\"Dataset loading failed. Please check Hugging Face access or try 'rotten_tomatoes' dataset.\")\n",
        "\n",
        "# Verify dataset structure\n",
        "print(\"Sample training data:\", dataset[\"train\"][0])"
      ],
      "metadata": {
        "id": "cupgiQfngcVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create synthetic ground-truth proposals (simplified for demo)\n",
        "def create_synthetic_proposal(sentence, label):\n",
        "    sentiment = \"positive\" if label == 1 else \"negative\"\n",
        "    problem = f\"Analyze sentiment in short texts like: '{sentence}'\"\n",
        "    hypothesis = f\"The {sentiment} sentiment can be detected using contextual embeddings.\"\n",
        "    methodology = \"Use a transformer-based model with fine-tuning on short-text datasets.\"\n",
        "    return f\"Problem: {problem}\\nHypothesis: {hypothesis}\\nMethodology: {methodology}\"\n",
        "\n",
        "# Prepare dataset with input-output pairs (fixed for batched processing)\n",
        "def preprocess_data(examples):\n",
        "    inputs = [f\"Propose a method for sentiment analysis of ambiguous short texts: {sentence}\" for sentence in examples[\"sentence\"]]\n",
        "    targets = [create_synthetic_proposal(sentence, label) for sentence, label in zip(examples[\"sentence\"], examples[\"label\"])]\n",
        "    return {\"input_text\": inputs, \"target_text\": targets}"
      ],
      "metadata": {
        "id": "T2HledkTgcVb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    train_data = dataset[\"train\"].map(preprocess_data, batched=True, remove_columns=[\"sentence\", \"label\", \"idx\"])\n",
        "    validation_data = dataset[\"validation\"].map(preprocess_data, batched=True, remove_columns=[\"sentence\", \"label\", \"idx\"])\n",
        "except Exception as e:\n",
        "    print(f\"Error in preprocessing: {e}\")\n",
        "    raise SystemExit(\"Preprocessing failed. Check dataset structure.\")\n",
        "\n",
        "# Create train-test-validation split from training data\n",
        "train_val_data = train_data.train_test_split(test_size=0.2, seed=42)  # 80% train, 20% temp\n",
        "val_test_data = train_val_data[\"test\"].train_test_split(test_size=0.5, seed=42)  # Split temp into 10% val, 10% test\n",
        "\n",
        "train_dataset = train_val_data[\"train\"]\n",
        "val_dataset = val_test_data[\"train\"]\n",
        "test_dataset = val_test_data[\"test\"]\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "hNp_DGCagcVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"google/flan-t5-small\"\n",
        "try:\n",
        "    tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model/tokenizer: {e}\")\n",
        "    raise SystemExit(\"Model loading failed. Check Hugging Face access.\")\n",
        "\n",
        "# Apply LoRA for efficient fine-tuning\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_2_SEQ_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "xyKNferggcVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "    inputs = tokenizer(examples[\"input_text\"], max_length=128, truncation=True, padding=\"max_length\")\n",
        "    targets = tokenizer(examples[\"target_text\"], max_length=256, truncation=True, padding=\"max_length\")\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True, remove_columns=[\"input_text\", \"target_text\"])\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True, remove_columns=[\"input_text\", \"target_text\"])\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True, remove_columns=[\"input_text\", \"target_text\"])"
      ],
      "metadata": {
        "id": "ha81wiZ8gcVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Adafactor\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, collate_fn=data_collator)\n",
        "\n",
        "\n",
        "optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
        "\n",
        "EPOCHS = 5\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print(f\"\\nüîÅ Epoch {epoch+1}/{EPOCHS}\")\n",
        "\n",
        "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        del input_ids, attention_mask, labels, outputs, loss, batch\n",
        "        gc.collect()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f\"‚úÖ Avg Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            del input_ids, attention_mask, labels, outputs, batch\n",
        "            gc.collect()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"üìâ Avg Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "# Plot loss curve\n",
        "plt.plot(train_losses, label=\"Training Loss\", marker='o')\n",
        "plt.plot(val_losses, label=\"Validation Loss\", marker='x')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mpWGcQgqgcVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load as load_metric\n",
        "from sentence_transformers import util, SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "# Metrics\n",
        "rouge = load_metric(\"rouge\")\n",
        "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, collate_fn=data_collator)\n",
        "model.eval()\n",
        "generated, references = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"]\n",
        "\n",
        "        generated_ids = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_new_tokens=32)\n",
        "        decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
        "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "        generated.extend(decoded_preds)\n",
        "        references.extend(decoded_labels)\n",
        "\n",
        "        del input_ids, attention_mask, labels, generated_ids, decoded_preds, decoded_labels, batch\n",
        "        gc.collect()\n",
        "\n",
        "# Compute metrics\n",
        "rouge_scores = rouge.compute(predictions=generated, references=references)\n",
        "print(\"üß™ Final Test ROUGE-L:\", rouge_scores[\"rougeL\"])\n",
        "\n",
        "sampled_preds = generated[:min(100, len(generated))]\n",
        "embeddings = sentence_model.encode(sampled_preds, convert_to_tensor=True, batch_size=16, show_progress_bar=False)\n",
        "cosine_scores = util.cos_sim(embeddings, embeddings).mean().item()\n",
        "novelty = 1 - cosine_scores\n",
        "\n",
        "relevance = sum(1 for pred in generated if \"Problem:\" in pred and \"Hypothesis:\" in pred and \"Methodology:\" in pred) / len(generated)\n",
        "\n",
        "print(f\"üß† Novelty Score: {novelty:.4f}\")\n",
        "print(f\"‚úÖ Relevance Score: {relevance:.4f}\")\n"
      ],
      "metadata": {
        "id": "9rhM8hYWMDw3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}